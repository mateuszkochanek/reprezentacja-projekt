{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a81647f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b5e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from datasets import N_ATTRS\n",
    "\n",
    "\n",
    "class MVAE(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_latents,\n",
    "                 image_encoder,\n",
    "                 image_decoder,\n",
    "                 text_encoder,\n",
    "                 text_decoder):\n",
    "        super(MVAE, self).__init__()\n",
    "        self.image_encoder = image_encoder\n",
    "        self.image_decoder = image_decoder\n",
    "        self.text_encoder = text_encoder\n",
    "        self.text_decoder = text_decoder\n",
    "        self.product_of_experts = ProductOfExperts()\n",
    "        self.n_latents = n_latents\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:  # return mean during inference\n",
    "            return mu\n",
    "\n",
    "    def forward(self, img_emb=None, text_emb=None):\n",
    "        mu, logvar = self.forward_encoder(img_emb, text_emb)\n",
    "        # reparametrization trick to sample\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        # reconstruct inputs based on that gaussian\n",
    "        image_recon, text_recon = self.forward_decoder(z)\n",
    "        return image_recon, text_recon, mu, logvar\n",
    "\n",
    "    def forward_encoder(self, img_emb=None, text_emb=None):\n",
    "        if img_emb is not None:\n",
    "            batch_size = img_emb.size(0)\n",
    "        else:\n",
    "            batch_size = text_emb.size(0)\n",
    "\n",
    "        use_cuda = next(self.parameters()).is_cuda  # check if CUDA\n",
    "        mu, logvar = prior_expert((1, batch_size, self.n_latents),\n",
    "                                  use_cuda=use_cuda)\n",
    "        if image is not None:\n",
    "            image_mu, image_logvar = self.image_encoder(img_emb)\n",
    "            mu = torch.cat((mu, image_mu.unsqueeze(0)), dim=0)\n",
    "            logvar = torch.cat((logvar, image_logvar.unsqueeze(0)), dim=0)\n",
    "\n",
    "        if text_emb is not None:\n",
    "            text_mu, text_logvar = self.text_encoder(text_emb)\n",
    "            mu = torch.cat((mu, text_mu.unsqueeze(0)), dim=0)\n",
    "            logvar = torch.cat((logvar, text_logvar.unsqueeze(0)), dim=0)\n",
    "\n",
    "        # product of experts to combine gaussians\n",
    "        mu, logvar = self.product_of_experts(mu, logvar)\n",
    "        return mu, logvar\n",
    "\n",
    "    def forward_decoder(self, z):\n",
    "        image_recon = self.image_decoder(z)\n",
    "        text_recon = self.text_decoder(z)\n",
    "        return image_recon, text_recon\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    \"\"\"https://arxiv.org/abs/1710.05941\"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * F.sigmoid(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Parametrizes q(z|x).\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_dims: int,\n",
    "                 hidden_dims: int,\n",
    "                 out_dim: int,\n",
    "                 last_activation: Type[nn.Module]\n",
    "                 ):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(in_dims, hidden_dims[0]),\n",
    "            nn.Swish(inplace=True),\n",
    "            *[\n",
    "                layer\n",
    "                for idx in range(len(hidden_dims) - 1)\n",
    "                for layer in (nn.Linear(hidden_dims[idx], hidden_dims[idx + 1]), nn.Swish(inplace=True))\n",
    "            ],\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(hidden_dims[-1], out_dim * 2),\n",
    "            last_activation(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_dim = self.out_dim\n",
    "        x = self.encode(x)\n",
    "        return x[:, :out_dim], x[:, out_dim:]\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Parametrizes p(x|z).\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_dims: int,\n",
    "                 hidden_dims: int,\n",
    "                 out_dim: int,\n",
    "                 last_activation: Type[nn.Module]\n",
    "                 ):\n",
    "        super(ImageDecoder, self).__init__()\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(in_dims, hidden_dims[0]),\n",
    "            nn.Swish(inplace=True),\n",
    "            *[\n",
    "                layer\n",
    "                for idx in range(len(hidden_dims) - 1)\n",
    "                for layer in (nn.Linear(hidden_dims[idx], hidden_dims[idx + 1]), nn.Swish(inplace=True))\n",
    "            ],\n",
    "            nn.Linear(hidden_dims[-1], out_dim * 2),\n",
    "            last_activation(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        # the input will be a vector of size |n_latents|\n",
    "        z = self.decode(z)\n",
    "        # returns reconstructed image/text embedding\n",
    "        return z  # NOTE: no sigmoid here. See train.py\n",
    "\n",
    "\n",
    "class ProductOfExperts(nn.Module):\n",
    "    \"\"\"Return parameters for product of independent experts.\n",
    "    See https://arxiv.org/pdf/1410.7827.pdf for equations.\n",
    "\n",
    "    @param mu: M x D for M experts\n",
    "    @param logvar: M x D for M experts\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, mu, logvar, eps=1e-8):\n",
    "        var = torch.exp(logvar) + eps\n",
    "        # precision of i-th Gaussian expert at point x\n",
    "        T = 1. / var\n",
    "        pd_mu = torch.sum(mu * T, dim=0) / torch.sum(T, dim=0)\n",
    "        pd_var = 1. / torch.sum(T, dim=0)\n",
    "        pd_logvar = torch.log(pd_var)\n",
    "        return pd_mu, pd_logvar\n",
    "\n",
    "\n",
    "def prior_expert(size, use_cuda=False):\n",
    "    \"\"\"Universal prior expert. Here we use a spherical\n",
    "    Gaussian: N(0, 1).\n",
    "\n",
    "    @param size: integer\n",
    "                 dimensionality of Gaussian\n",
    "    @param use_cuda: boolean [default: False]\n",
    "                     cast CUDA on variables\n",
    "    \"\"\"\n",
    "    mu = Variable(torch.zeros(size))\n",
    "    logvar = Variable(torch.log(torch.ones(size)))\n",
    "    if use_cuda:\n",
    "        mu, logvar = mu.cuda(), logvar.cuda()\n",
    "    return mu, logvar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f583db0",
   "metadata": {},
   "source": [
    "# TRain/Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f78d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "from model import MVAE\n",
    "\n",
    "\n",
    "def elbo_loss(recon_img_emb, image_emb, recon_text_emb, text_emb, mu, logvar,\n",
    "              lambda_image=1.0, lambda_text=1.0, annealing_factor=1):\n",
    "    \"\"\"Bimodal ELBO loss function.\n",
    "\n",
    "    @param recon_image: torch.Tensor\n",
    "                        reconstructed image\n",
    "    @param image: torch.Tensor\n",
    "                  input image\n",
    "    @param recon_attrs: torch.Tensor\n",
    "                        reconstructed attribute probabilities\n",
    "    @param attrs: torch.Tensor\n",
    "                  input attributes\n",
    "    @param mu: torch.Tensor\n",
    "               mean of latent distribution\n",
    "    @param logvar: torch.Tensor\n",
    "                   log-variance of latent distribution\n",
    "    @param lambda_image: float [default: 1.0]\n",
    "                         weight for image BCE\n",
    "    @param lambda_attrs: float [default: 1.0]\n",
    "                       weight for attribute BCE\n",
    "    @param annealing_factor: integer [default: 1]\n",
    "                             multiplier for KL divergence term\n",
    "    @return ELBO: torch.Tensor\n",
    "                  evidence lower bound\n",
    "    \"\"\"\n",
    "    image_bce, attrs_bce = 0, 0  # default params\n",
    "\n",
    "    if recon_img_emb is not None and image_emb is not None:\n",
    "        image_bce = torch.sum(binary_cross_entropy_with_logits(recon_img_emb, image_emb))\n",
    "\n",
    "    if recon_text_emb is not None and text_emb is not None:\n",
    "        text_bce = torch.sum(binary_cross_entropy_with_logits(recon_text_emb, text_emb))\n",
    "\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "    ELBO = torch.mean(lambda_image * image_bce + lambda_text * text_bce + annealing_factor * KLD)\n",
    "    return ELBO\n",
    "\n",
    "\n",
    "def binary_cross_entropy_with_logits(input, target):\n",
    "    \"\"\"Sigmoid Activation + Binary Cross Entropy\n",
    "\n",
    "    @param input: torch.Tensor (size N)\n",
    "    @param target: torch.Tensor (size N)\n",
    "    @return loss: torch.Tensor (size N)\n",
    "    \"\"\"\n",
    "    if not (target.size() == input.size()):\n",
    "        raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(\n",
    "            target.size(), input.size()))\n",
    "\n",
    "    return (torch.clamp(input, 0) - input * target\n",
    "            + torch.log(1 + torch.exp(-torch.abs(input))))\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, folder='./', filename='checkpoint.pth.tar'):\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "    torch.save(state, os.path.join(folder, filename))\n",
    "    if is_best:\n",
    "        shutil.copyfile(os.path.join(folder, filename),\n",
    "                        os.path.join(folder, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def load_checkpoint(file_path, use_cuda=False):\n",
    "    checkpoint = torch.load(file_path) if use_cuda else \\\n",
    "        torch.load(file_path, map_location=lambda storage, location: storage)\n",
    "    model = MVAE(checkpoint['n_latents'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(epoch, lambda_img_emb, lambda_text_emb):\n",
    "    model.train()\n",
    "    train_loss_meter = AverageMeter()\n",
    "\n",
    "    # NOTE: is_paired is 1 if the example is paired\n",
    "    for batch_idx, (img_emb, text_emb) in enumerate(train_loader):\n",
    "        annealing_factor = 1.0\n",
    "\n",
    "        if args.cuda:\n",
    "            img_emb = img_emb.cuda()\n",
    "            text_emb = text_emb.cuda()\n",
    "        img_emb = Variable(img_emb)\n",
    "        text_emb = Variable(text_emb)\n",
    "        batch_size = len(image_emb)\n",
    "\n",
    "        # refresh the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss = 0  # accumulate train loss here so we don't store a lot of things.\n",
    "\n",
    "        # compute ELBO using all data (``complete\")\n",
    "        recon_img_emb, recon_text_emb, mu, logvar = model(img_emb, text_emb)\n",
    "        train_loss += elbo_loss(recon=[recon_img_emb] + [recon_text_emb],\n",
    "                                data=[img_emb] + [text_emb],\n",
    "                                mu=mu,\n",
    "                                logvar=logvar,\n",
    "                                lambda_img_emb=lambda_img_emb,\n",
    "                                lambda_attrs=lambda_text_emb,\n",
    "                                annealing_factor=annealing_factor)\n",
    "\n",
    "        # compute ELBO using only img_emb data\n",
    "        recon_img_emb, _, mu, logvar = model(img_emb=img_emb)\n",
    "        train_loss += elbo_loss(recon=[recon_img_emb],\n",
    "                                data=[img_emb],\n",
    "                                mu=mu,\n",
    "                                logvar=logvar,\n",
    "                                lambda_img_emb=lambda_img_emb,\n",
    "                                lambda_attrs=lambda_text_emb,\n",
    "                                annealing_factor=annealing_factor)\n",
    "\n",
    "        # compute ELBO using only text data\n",
    "        _, recon_text_emb, mu, logvar = model(text_emb=text_emb)\n",
    "        train_loss += elbo_loss(recon=[recon_text_emb],\n",
    "                                data=[text_emb],\n",
    "                                mu=mu,\n",
    "                                logvar=logvar,\n",
    "                                lambda_img_emb=lambda_img_emb,\n",
    "                                lambda_attrs=lambda_text_emb,\n",
    "                                annealing_factor=annealing_factor)\n",
    "\n",
    "        # compute and take gradient step\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAnnealing-Factor: {:.3f}'.format(\n",
    "                epoch, batch_idx * len(image_emb), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), train_loss_meter.avg, annealing_factor))\n",
    "\n",
    "    print('====> Epoch: {}\\tLoss: {:.4f}'.format(epoch, train_loss_meter.avg))\n",
    "\n",
    "\n",
    "def test(epoch, lambda_img_emb, lambda_text_emb):\n",
    "    model.eval()\n",
    "    test_loss_meter = AverageMeter()\n",
    "\n",
    "    pbar = tqdm(total=len(test_loader))\n",
    "    for batch_idx, (img_emb, txt_emb) in enumerate(test_loader):\n",
    "        if args.cuda:\n",
    "            img_emb = img_emb.cuda()\n",
    "            attrs = attrs.cuda()\n",
    "\n",
    "        img_emb = Variable(img_emb, volatile=True)\n",
    "        attrs = Variable(attrs, volatile=True)\n",
    "        batch_size = len(img_emb)\n",
    "\n",
    "        test_loss = 0  # accumulate train loss here so we don't store a lot of things.\n",
    "\n",
    "        # compute ELBO using all data (``complete\")\n",
    "        recon_img_emb, recon_text_emb, mu, logvar = model(img_emb, text_emb)\n",
    "        test_loss += elbo_loss(recon=[recon_img_emb] + [recon_text_emb],\n",
    "                               data=[img_emb] + [text_emb],\n",
    "                               mu=mu,\n",
    "                               logvar=logvar,\n",
    "                               lambda_img_emb=lambda_img_emb,\n",
    "                               lambda_attrs=lambda_text_emb,\n",
    "                               annealing_factor=annealing_factor)\n",
    "\n",
    "        # compute ELBO using only img_emb data\n",
    "        recon_img_emb, _, mu, logvar = model(img_emb=img_emb)\n",
    "        test_loss += elbo_loss(recon=[recon_img_emb],\n",
    "                               data=[img_emb],\n",
    "                               mu=mu,\n",
    "                               logvar=logvar,\n",
    "                               lambda_img_emb=lambda_img_emb,\n",
    "                               lambda_attrs=lambda_text_emb,\n",
    "                               annealing_factor=annealing_factor)\n",
    "\n",
    "        # compute ELBO using only text data\n",
    "        _, recon_text_emb, mu, logvar = model(text_emb=text_emb)\n",
    "        test_loss += elbo_loss(recon=[recon_text_emb],\n",
    "                               data=[text_emb],\n",
    "                               mu=mu,\n",
    "                               logvar=logvar,\n",
    "                               lambda_img_emb=lambda_img_emb,\n",
    "                               lambda_attrs=lambda_text_emb,\n",
    "                               annealing_factor=annealing_factor)\n",
    "        test_loss_meter.update(test_loss.data[0], batch_size)\n",
    "        pbar.update()\n",
    "\n",
    "    pbar.close()\n",
    "    print('====> Test Loss: {:.4f}'.format(test_loss_meter.avg))\n",
    "    return test_loss_meter.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70244b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = sys.maxint\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    loss      = test(epoch)\n",
    "    is_best   = loss < best_loss\n",
    "    best_loss = min(loss, best_loss)\n",
    "    # save the best model and current model\n",
    "    save_checkpoint({\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_loss': best_loss,\n",
    "        'n_latents': args.n_latents,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best, folder='./trained_models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
