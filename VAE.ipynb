{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837b79ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc395514360f49158eab99d2b2bba6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9262702fc1646f1ae517e36d17be375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/11.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cc6204-hackaton-cub-dataset/default to /home/erthax/.cache/huggingface/datasets/alkzar90___cc6204-hackaton-cub-dataset/default/0.0.0/de850c9086bff0dd6d6eab90f79346241178f65e1a016a50eec240ae9cdf2064...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dab62ec04b4527bc210a15735a65fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed81e207cf6b41f793c79424687a4708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/12.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cc6204-hackaton-cub-dataset downloaded and prepared to /home/erthax/.cache/huggingface/datasets/alkzar90___cc6204-hackaton-cub-dataset/default/0.0.0/de850c9086bff0dd6d6eab90f79346241178f65e1a016a50eec240ae9cdf2064. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5b1a5e08d443e29630f660b9125ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"alkzar90/CC6204-Hackaton-Cub-Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c9273",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4cb75ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">torch.nn</span> <span class=\"k\">as</span> <span class=\"nn\">nn</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">class</span> <span class=\"nc\">BaseAutoEncoder</span><span class=\"p\">(</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n",
       "    <span class=\"sd\">&quot;&quot;&quot;Base AutoEncoder module class.&quot;&quot;&quot;</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">encoder</span><span class=\"p\">:</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"n\">decoder</span><span class=\"p\">:</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">,</span> <span class=\"n\">n_latent_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span><span class=\"p\">):</span>\n",
       "        <span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"sd\">        :param encoder: encoder network</span>\n",
       "<span class=\"sd\">        :param decoder: decoder network</span>\n",
       "<span class=\"sd\">        :param n_latent_features: number of latent features in the AE</span>\n",
       "<span class=\"sd\">        &quot;&quot;&quot;</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">n_latent_features</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"n\">n_latent_features</span>\n",
       "\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"p\">:</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span> <span class=\"o\">=</span> <span class=\"n\">encoder</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder</span><span class=\"p\">:</span> <span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span> <span class=\"o\">=</span> <span class=\"n\">decoder</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">:</span>\n",
       "        <span class=\"sd\">&quot;&quot;&quot;Forward function for mapping input to output.&quot;&quot;&quot;</span>\n",
       "        <span class=\"n\">z</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder_forward</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder_forward</span><span class=\"p\">(</span><span class=\"n\">z</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">encoder_forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">:</span>\n",
       "        <span class=\"sd\">&quot;&quot;&quot; Function to perform forward pass through encoder network.</span>\n",
       "\n",
       "<span class=\"sd\">        takes: tensor of shape [batch_size x input_flattened_size] (flattened input)</span>\n",
       "<span class=\"sd\">        returns: tensor of shape [batch_size x latent_feature_size] (latent vector)</span>\n",
       "<span class=\"sd\">        &quot;&quot;&quot;</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"ne\">NotImplementedError</span><span class=\"p\">()</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">decoder_forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">z</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">:</span>\n",
       "        <span class=\"sd\">&quot;&quot;&quot; Function to perform forward pass through decoder network.</span>\n",
       "\n",
       "<span class=\"sd\">        takes: tensor of shape [batch_size x latent_feature_size] (latent vector)</span>\n",
       "<span class=\"sd\">        returns: tensor of shape [batch_size x output_flattened_size] (flettened output)</span>\n",
       "<span class=\"sd\">        &quot;&quot;&quot;</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"ne\">NotImplementedError</span><span class=\"p\">()</span>\n",
       "        \n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{torch}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{nn} \\PY{k}{as} \\PY{n+nn}{nn}\n",
       "\n",
       "\n",
       "\\PY{k}{class} \\PY{n+nc}{BaseAutoEncoder}\\PY{p}{(}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Module}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}Base AutoEncoder module class.\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{encoder}\\PY{p}{:} \\PY{n}{nn}\\PY{o}{.}\\PY{n}{Module}\\PY{p}{,} \\PY{n}{decoder}\\PY{p}{:} \\PY{n}{nn}\\PY{o}{.}\\PY{n}{Module}\\PY{p}{,} \\PY{n}{n\\PYZus{}latent\\PYZus{}features}\\PY{p}{:} \\PY{n+nb}{int}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{l+s+sd}{        :param encoder: encoder network}\n",
       "\\PY{l+s+sd}{        :param decoder: decoder network}\n",
       "\\PY{l+s+sd}{        :param n\\PYZus{}latent\\PYZus{}features: number of latent features in the AE}\n",
       "\\PY{l+s+sd}{        \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{n\\PYZus{}latent\\PYZus{}features}\\PY{p}{:} \\PY{n+nb}{int} \\PY{o}{=} \\PY{n}{n\\PYZus{}latent\\PYZus{}features}\n",
       "\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder}\\PY{p}{:} \\PY{n}{nn}\\PY{o}{.}\\PY{n}{Module} \\PY{o}{=} \\PY{n}{encoder}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder}\\PY{p}{:} \\PY{n}{nn}\\PY{o}{.}\\PY{n}{Module} \\PY{o}{=} \\PY{n}{decoder}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{forward}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{:} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{:}\n",
       "        \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}Forward function for mapping input to output.\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "        \\PY{n}{z} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder\\PYZus{}forward}\\PY{p}{(}\\PY{n}{x}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder\\PYZus{}forward}\\PY{p}{(}\\PY{n}{z}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{encoder\\PYZus{}forward}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{:} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{:}\n",
       "        \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{} Function to perform forward pass through encoder network.}\n",
       "\n",
       "\\PY{l+s+sd}{        takes: tensor of shape [batch\\PYZus{}size x input\\PYZus{}flattened\\PYZus{}size] (flattened input)}\n",
       "\\PY{l+s+sd}{        returns: tensor of shape [batch\\PYZus{}size x latent\\PYZus{}feature\\PYZus{}size] (latent vector)}\n",
       "\\PY{l+s+sd}{        \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "        \\PY{k}{raise} \\PY{n+ne}{NotImplementedError}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{decoder\\PYZus{}forward}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{z}\\PY{p}{:} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{Tensor}\\PY{p}{:}\n",
       "        \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{} Function to perform forward pass through decoder network.}\n",
       "\n",
       "\\PY{l+s+sd}{        takes: tensor of shape [batch\\PYZus{}size x latent\\PYZus{}feature\\PYZus{}size] (latent vector)}\n",
       "\\PY{l+s+sd}{        returns: tensor of shape [batch\\PYZus{}size x output\\PYZus{}flattened\\PYZus{}size] (flettened output)}\n",
       "\\PY{l+s+sd}{        \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "        \\PY{k}{raise} \\PY{n+ne}{NotImplementedError}\\PY{p}{(}\\PY{p}{)}\n",
       "        \n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import torch\n",
       "import torch.nn as nn\n",
       "\n",
       "\n",
       "class BaseAutoEncoder(nn.Module):\n",
       "    \"\"\"Base AutoEncoder module class.\"\"\"\n",
       "\n",
       "    def __init__(self, encoder: nn.Module, decoder: nn.Module, n_latent_features: int):\n",
       "        \"\"\"\n",
       "        :param encoder: encoder network\n",
       "        :param decoder: decoder network\n",
       "        :param n_latent_features: number of latent features in the AE\n",
       "        \"\"\"\n",
       "        super().__init__()\n",
       "\n",
       "        self.n_latent_features: int = n_latent_features\n",
       "\n",
       "        self.encoder: nn.Module = encoder\n",
       "        self.decoder: nn.Module = decoder\n",
       "\n",
       "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
       "        \"\"\"Forward function for mapping input to output.\"\"\"\n",
       "        z = self.encoder_forward(x)\n",
       "        return self.decoder_forward(z)\n",
       "\n",
       "    def encoder_forward(self, x: torch.Tensor) -> torch.Tensor:\n",
       "        \"\"\" Function to perform forward pass through encoder network.\n",
       "\n",
       "        takes: tensor of shape [batch_size x input_flattened_size] (flattened input)\n",
       "        returns: tensor of shape [batch_size x latent_feature_size] (latent vector)\n",
       "        \"\"\"\n",
       "        raise NotImplementedError()\n",
       "\n",
       "    def decoder_forward(self, z: torch.Tensor) -> torch.Tensor:\n",
       "        \"\"\" Function to perform forward pass through decoder network.\n",
       "\n",
       "        takes: tensor of shape [batch_size x latent_feature_size] (latent vector)\n",
       "        returns: tensor of shape [batch_size x output_flattened_size] (flettened output)\n",
       "        \"\"\"\n",
       "        raise NotImplementedError()\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import Code, display\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.ae import BaseAutoEncoder\n",
    "\n",
    "np.random.seed(2021)\n",
    "torch.manual_seed(2021)\n",
    "\n",
    "display(Code(filename=\"src/ae.py\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1892371d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mVEncoder\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"Encoder for VAE.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      6\u001b[0m         n_input_features: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m      7\u001b[0m         n_hidden_neurons: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m      8\u001b[0m         n_latent_features: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m      9\u001b[0m     ):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class VEncoder(nn.Module):\n",
    "    \"\"\"Encoder for VAE.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_features: int,\n",
    "        n_hidden_neurons: int,\n",
    "        n_latent_features: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_input_features: number of input features (28 x 28 = 784 for MNIST)\n",
    "        :param n_hidden_neurons: number of neurons in hidden FC layer\n",
    "        :param n_latent_features: size of the latent vector\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_to_hidden = nn.Linear(n_input_features, n_hidden_neurons)\n",
    "        self.hidden_to_latent_loc = nn.Linear(n_hidden_neurons, n_latent_features)\n",
    "        self.hidden_to_latent_scale = nn.Linear(n_hidden_neurons, n_latent_features)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sfplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Encode data to gaussian distribution params.\"\"\"\n",
    "        z_loc = None\n",
    "        z_scale = None\n",
    "        \n",
    "        x = self.input_to_hidden(x)\n",
    "        \n",
    "        x_loc = self.relu(x)\n",
    "        z_loc = self.hidden_to_latent_loc(x_loc)\n",
    "        \n",
    "        x_scale = self.sfplus(x)\n",
    "        z_scale = torch.exp(self.hidden_to_latent_scale(x_loc))\n",
    "        \n",
    "        return z_loc, z_scale\n",
    "    \n",
    "\n",
    "class VDecoder(nn.Module):\n",
    "    \"\"\"Decoder for VAE.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_latent_features: int, \n",
    "        n_hidden_neurons: int, \n",
    "        n_output_features: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_latent_features: number of latent features (same as in Encoder)\n",
    "        :param n_hidden_neurons: number of neurons in hidden FC layer\n",
    "        :param n_output_features: size of the output vector (28 x 28 = 784 for MNIST)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_latent_features, n_hidden_neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden_neurons, n_output_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decode latent vector to image.\"\"\"\n",
    "        r = self.net(z)\n",
    "        return r\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(BaseAutoEncoder):\n",
    "    \"\"\"Variational Auto Encoder model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_data_features: int,\n",
    "        n_encoder_hidden_features: int,\n",
    "        n_decoder_hidden_features: int,\n",
    "        n_latent_features: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_data_features: number of input and output features (28 x 28 = 784 for MNIST)\n",
    "        :param n_encoder_hidden_features: number of neurons in encoder's hidden layer\n",
    "        :param n_decoder_hidden_features: number of neurons in decoder's hidden layer\n",
    "        :param n_latent_features: number of latent features\n",
    "        \"\"\"\n",
    "        encoder = VEncoder(\n",
    "            n_input_features=n_data_features,\n",
    "            n_hidden_neurons=n_encoder_hidden_features,\n",
    "            n_latent_features=n_latent_features,\n",
    "        )\n",
    "        decoder = VDecoder(\n",
    "            n_latent_features=n_latent_features,\n",
    "            n_hidden_neurons=n_decoder_hidden_features,\n",
    "            n_output_features=n_data_features,\n",
    "        )\n",
    "        super().__init__(\n",
    "            encoder=encoder, decoder=decoder, n_latent_features=n_latent_features\n",
    "        )\n",
    "        self.input_shape = None\n",
    "\n",
    "    def encoder_forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Function to perform forward pass through encoder network.\n",
    "        takes: tensor of shape [batch_size x [image-size]] (input images batch)\n",
    "        returns: tensor of shape [batch_size x latent_feature_size] (latent vector)\n",
    "        \"\"\"\n",
    "        z = None\n",
    "        if self.input_shape is None:\n",
    "            self.input_shape = x.shape[1:]\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        mu, sigma = self.encoder.forward(x)\n",
    "        z = dist.Normal(mu, sigma).sample()\n",
    "        return z\n",
    "\n",
    "    def decoder_forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Function to perform forward pass through decoder network.\n",
    "        takes: tensor of shape [batch_size x latent_feature_size] (latent vector)\n",
    "        returns: tensor of shape [batch_size x [image-size]] (reconstructed images batch)\n",
    "        \"\"\"\n",
    "        r = None\n",
    "        r = self.decoder(z)\n",
    "        return r.view(-1, *self.input_shape)\n",
    "\n",
    "    def model(self, x: torch.Tensor):\n",
    "        \"\"\"Pyro model for VAE; p(x|z)p(z).\"\"\"\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            z_loc = torch.zeros((x.shape[0], self.n_latent_features))\n",
    "            z_scale = torch.ones((x.shape[0], self.n_latent_features))\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            output = self.decoder.forward(z).view(-1, *self.input_shape)\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(output).to_event(3), obs=x)\n",
    "\n",
    "    def guide(self, x: torch.Tensor):\n",
    "        \"\"\"Pyro guide for VAE; q(z|x)\"\"\"\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            z_loc, z_scale = self.encoder.forward(x.view(x.shape[0], -1))\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a07f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
