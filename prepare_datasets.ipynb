{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df4652a5-8aa6-4521-a900-66bb238d45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Type\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import normalize as normalize_emb\n",
    "from torchvision import models as tv_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fc1e33f7-0af8-4f1b-99b2-af8b5dc6aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    # Transformations\n",
    "    resize = T.Resize((224, 224))\n",
    "    normalize = T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "    pil_to_image = T.PILToTensor()\n",
    "    # Get models used to preprocess features\n",
    "    mini_lm = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    resnet = tv_models.resnet50(pretrained=True)\n",
    "    resnet.eval()\n",
    "    resnet.fc = nn.Identity()\n",
    "    # Preprocess\n",
    "    preprocessed = []\n",
    "    for sample in tqdm(\n",
    "        iterable=dataset,\n",
    "        total=dataset.num_rows,\n",
    "        desc=\"Processing data\",\n",
    "    ):\n",
    "        image = sample[\"image\"]\n",
    "        label = sample[\"label\"]\n",
    "        # There are 4 images in \"L\" format\n",
    "        if sample[\"image\"].mode == \"L\":\n",
    "            continue\n",
    "        image = pil_to_image(image).float()\n",
    "        resized_img = resize(image)\n",
    "        normalized_img = normalize(resized_img)\n",
    "        for description in sample[\"description\"].split(\"\\n\"):\n",
    "            if not description:\n",
    "                continue\n",
    "            with torch.no_grad():\n",
    "                # Added batch dim\n",
    "                img_emb = resnet(normalized_img.unsqueeze(dim=0))\n",
    "                text_emb = mini_lm.encode(\n",
    "                    sentences=description,\n",
    "                    convert_to_tensor=True,\n",
    "                )\n",
    "            preprocessed.append(\n",
    "                {\n",
    "                    \"img_emb\": normalize_emb(img_emb[0], dim=0), # Drop batch dim\n",
    "                    \"text_emb\": normalize_emb(text_emb, dim=0),\n",
    "                    \"image\": resized_img,\n",
    "                    \"text\": description,\n",
    "                    \"label\": sample[\"label\"],\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1b81b4-c67f-41f8-9c95-2b79e0eeb776",
   "metadata": {},
   "source": [
    "## Preprocess Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aaf8efd9-c2e2-42b2-8d98-5b7fac250f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cc6204-hackaton-cub-dataset (/home/cicheck/.cache/huggingface/datasets/alkzar90___cc6204-hackaton-cub-dataset/default/0.0.0/de850c9086bff0dd6d6eab90f79346241178f65e1a016a50eec240ae9cdf2064)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540c8f37b67c4a49a5e964c3c65648a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"alkzar90/CC6204-Hackaton-Cub-Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5c1278c0-0987-455f-a043-0f53d42241e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|████████████████████████████████████████████████████████████████| 5994/5994 [41:24<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train = preprocess_data(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fa49fb8c-bbc0-475f-99c4-f725e2771910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_emb</th>\n",
       "      <th>text_emb</th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tensor(0.0176), tensor(0.0005), tensor(0.0025...</td>\n",
       "      <td>[tensor(0.0832, device='cuda:0'), tensor(0.064...</td>\n",
       "      <td>[[[tensor(159.5414), tensor(161.8534), tensor(...</td>\n",
       "      <td>this bird is brown with a lighter brown crest.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tensor(0.0176), tensor(0.0005), tensor(0.0025...</td>\n",
       "      <td>[tensor(0.0553, device='cuda:0'), tensor(0.112...</td>\n",
       "      <td>[[[tensor(159.5414), tensor(161.8534), tensor(...</td>\n",
       "      <td>aquatic large bird with long hooked bill, whit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             img_emb  \\\n",
       "0  [tensor(0.0176), tensor(0.0005), tensor(0.0025...   \n",
       "1  [tensor(0.0176), tensor(0.0005), tensor(0.0025...   \n",
       "\n",
       "                                            text_emb  \\\n",
       "0  [tensor(0.0832, device='cuda:0'), tensor(0.064...   \n",
       "1  [tensor(0.0553, device='cuda:0'), tensor(0.112...   \n",
       "\n",
       "                                               image  \\\n",
       "0  [[[tensor(159.5414), tensor(161.8534), tensor(...   \n",
       "1  [[[tensor(159.5414), tensor(161.8534), tensor(...   \n",
       "\n",
       "                                                text  label  \n",
       "0     this bird is brown with a lighter brown crest.      0  \n",
       "1  aquatic large bird with long hooked bill, whit...      0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "34b9eaea-a55e-4a6f-96f1-12899b74cf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59900, 5)\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e4389c0e-de73-4fed-b7a9-490898ef925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train.to_pickle(\"data/cub/preprocessed_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8862ca7a-130b-452c-aff6-927e4fd44979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cicheck/.pyenv/versions/3.10.2/envs/representation/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/cicheck/.pyenv/versions/3.10.2/envs/representation/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Processing data: 100%|████████████████████████████████████████████████████████████████| 5794/5794 [40:48<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_test = preprocess_data(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0e25463b-47ab-4977-96ae-a0cdac3ee659",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test.to_pickle(\"data/cub/preprocessed_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b8dba-f5d7-44ec-86af-356780b66517",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bd07d-2dcf-413d-b244-d51ddafc9460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
