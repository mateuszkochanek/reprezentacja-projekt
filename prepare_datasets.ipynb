{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df4652a5-8aa6-4521-a900-66bb238d45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Type\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import normalize as normalize_emb\n",
    "from torchvision import models as tv_models\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a345ac-016f-4eb1-baa5-a095e377b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc1e33f7-0af8-4f1b-99b2-af8b5dc6aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    # Transformations\n",
    "    resize = T.Resize((224, 224))\n",
    "    normalize = T.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "    pil_to_image = T.PILToTensor()\n",
    "    # Get models used to preprocess features\n",
    "    mini_lm = SentenceTransformer(\"all-MiniLM-L6-v2\").to(DEVICE)\n",
    "    resnet = tv_models.resnet50(pretrained=True).to(DEVICE)\n",
    "    resnet.eval()\n",
    "    resnet.fc = nn.Identity()\n",
    "    # Preprocess\n",
    "    preprocessed = []\n",
    "    for sample in tqdm(\n",
    "        iterable=dataset,\n",
    "        total=len(dataset),\n",
    "        desc=\"Processing data\",\n",
    "    ):\n",
    "        image = sample[\"image\"]\n",
    "        label = sample[\"label\"]\n",
    "        # There are 4 images in \"L\" format\n",
    "        if sample[\"image\"].mode == \"L\" or sample[\"image\"].mode == \"RGBA\":\n",
    "            continue\n",
    "        image = pil_to_image(image).float().to(DEVICE)\n",
    "        resized_img = resize(image)\n",
    "        normalized_img = normalize(resized_img)\n",
    "        for description in sample[\"description\"].split(\"\\n\"):\n",
    "            if not description:\n",
    "                continue\n",
    "            with torch.no_grad():\n",
    "                # Added batch dim\n",
    "                img_emb = resnet(normalized_img.unsqueeze(dim=0))\n",
    "                text_emb = mini_lm.encode(\n",
    "                    sentences=description,\n",
    "                    convert_to_tensor=True,\n",
    "                )\n",
    "            preprocessed.append(\n",
    "                {\n",
    "                    \"img_emb\": normalize_emb(img_emb[0], dim=0), # Drop batch dim\n",
    "                    \"text_emb\": normalize_emb(text_emb, dim=0),\n",
    "                    \"image_index\": sample[\"img_index\"],\n",
    "                    \"text\": description,\n",
    "                    \"label\": sample[\"label\"],\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1b81b4-c67f-41f8-9c95-2b79e0eeb776",
   "metadata": {},
   "source": [
    "## Preprocess Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12147714-c90d-4446-8a2b-d6b9e194f8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/cub/’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data/cub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf8efd9-c2e2-42b2-8d98-5b7fac250f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cc6204-hackaton-cub-dataset (/home/erthax/.cache/huggingface/datasets/alkzar90___cc6204-hackaton-cub-dataset/default/0.0.0/de850c9086bff0dd6d6eab90f79346241178f65e1a016a50eec240ae9cdf2064)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8358c1741bf4a0d8a070d0c905e3c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"alkzar90/CC6204-Hackaton-Cub-Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd1cc3e-7db5-4fc1-8c9d-c645918f970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orginal type is not mutable\n",
    "dataset = {\n",
    "    \"train\": list(dataset[\"train\"]),\n",
    "    \"test\": list(dataset[\"test\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b777be22-c265-471e-8f70-ab6fdace3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"test\"]:\n",
    "    for index, sample in enumerate(dataset[split]):\n",
    "        sample[\"img_index\"] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1278c0-0987-455f-a043-0f53d42241e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erthax/Programming/Uczenie Reprezentacji/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/erthax/Programming/Uczenie Reprezentacji/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Processing data: 100%|██████████████████████| 5994/5994 [05:06<00:00, 19.58it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train = preprocess_data(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4389c0e-de73-4fed-b7a9-490898ef925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train.to_pickle(\"data/cub/preprocessed_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8862ca7a-130b-452c-aff6-927e4fd44979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erthax/Programming/Uczenie Reprezentacji/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/erthax/Programming/Uczenie Reprezentacji/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Processing data: 100%|██████████████████████| 5794/5794 [04:49<00:00, 20.04it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_test = preprocess_data(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e25463b-47ab-4977-96ae-a0cdac3ee659",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test.to_pickle(\"data/cub/preprocessed_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ec3ea-a0df-4d3d-8cf6-e036ac8ac9e5",
   "metadata": {},
   "source": [
    "## Preprocess Hatefull Meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62218218-3267-4ef3-afb8-28b4ebb407ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/heatfull_meme/’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data/heatfull_meme/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "623bd07d-2dcf-413d-b244-d51ddafc9460",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(path_or_buf=\"data/heatfull_meme/data/train.jsonl\", lines=True)\n",
    "test = pd.read_json(path_or_buf=\"data/heatfull_meme/data/dev.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc6e1df5-6828-4c7b-b5f2-edce45d30414",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.to_dict(\"records\")\n",
    "test = test.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9820a8fd-1e79-4fd5-ab26-404151dde6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [train, test]:\n",
    "    for sample in split:\n",
    "        sample[\"img_index\"] = sample.pop(\"id\")\n",
    "        sample[\"description\"] = sample.pop(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74856c21-0c01-49ed-8125-d14cf082a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24d426af-b144-4c2e-9c44-44fe5360fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ed9a8ab-6fd5-47b9-b59e-f3e37159a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train:\n",
    "    img = Image.open(f\"data/heatfull_meme/data/{sample['img']}\")\n",
    "    sample[\"image\"] = copy.deepcopy(img)\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215104f7-35fa-4e6e-a0b0-d6472a8fa952",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in test:\n",
    "    img = Image.open(f\"data/heatfull_meme/data/{sample['img']}\")\n",
    "    sample[\"image\"] = copy.deepcopy(img)\n",
    "    img.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b05b24d-0181-40be-97a0-de741b937d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erthax/Programming/Uczenie Reprezentacji/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/erthax/Programming/Uczenie Reprezentacji/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Processing data: 100%|█████████████████████| 8500/8500 [00:53<00:00, 159.55it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train = preprocess_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9099190-e02f-469b-864d-733fdb0595ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train.to_pickle(\"data/heatfull_meme/preprocessed_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa267f01-e24f-4493-bf15-99aa362c6d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erthax/Programming/Uczenie Reprezentacji/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/erthax/Programming/Uczenie Reprezentacji/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Processing data: 100%|███████████████████████| 500/500 [00:03<00:00, 153.86it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_test = preprocess_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "566e4303-75cf-42cc-8753-edb532fe2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test.to_pickle(\"data/heatfull_meme/preprocessed_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb5d47-0861-4cc6-ae0f-ec71425980ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
